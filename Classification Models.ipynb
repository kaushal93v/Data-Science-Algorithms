{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative vs Generative Models - Bayesian Classifier & Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training data\n",
    "train_data <- read.csv(\"Task1E_train.csv\")\n",
    "train_label <- train_data[1:nrow(train_data),3] #creating the training labels\n",
    "\n",
    "#loading testing data\n",
    "test_data <- read.csv(\"Task1E_test.csv\")\n",
    "test_label <- test_data[1:nrow(test_data),3] #creating the testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.4367052</td><td>3.171451  </td><td>-1        </td></tr>\n",
       "\t<tr><td> 5.1048972</td><td>1.227815  </td><td> 1        </td></tr>\n",
       "\t<tr><td> 3.9974518</td><td>1.049502  </td><td> 1        </td></tr>\n",
       "\t<tr><td> 2.5354540</td><td>1.242902  </td><td> 1        </td></tr>\n",
       "\t<tr><td> 4.2624556</td><td>2.551909  </td><td> 1        </td></tr>\n",
       "\t<tr><td> 1.5505866</td><td>2.595164  </td><td>-1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " x1 & x2 & y\\\\\n",
       "\\hline\n",
       "\t -0.4367052 & 3.171451   & -1        \\\\\n",
       "\t  5.1048972 & 1.227815   &  1        \\\\\n",
       "\t  3.9974518 & 1.049502   &  1        \\\\\n",
       "\t  2.5354540 & 1.242902   &  1        \\\\\n",
       "\t  4.2624556 & 2.551909   &  1        \\\\\n",
       "\t  1.5505866 & 2.595164   & -1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | x2 | y | \n",
       "|---|---|---|---|---|---|\n",
       "| -0.4367052 | 3.171451   | -1         | \n",
       "|  5.1048972 | 1.227815   |  1         | \n",
       "|  3.9974518 | 1.049502   |  1         | \n",
       "|  2.5354540 | 1.242902   |  1         | \n",
       "|  4.2624556 | 2.551909   |  1         | \n",
       "|  1.5505866 | 2.595164   | -1         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1         x2       y \n",
       "1 -0.4367052 3.171451 -1\n",
       "2  5.1048972 1.227815  1\n",
       "3  3.9974518 1.049502  1\n",
       "4  2.5354540 1.242902  1\n",
       "5  4.2624556 2.551909  1\n",
       "6  1.5505866 2.595164 -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>-1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item -1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. -1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1  1  1  1  1 -1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train_data) #printing first few rows\n",
    "head(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 3.4781571 </td><td>-0.51546992</td><td> 1         </td></tr>\n",
       "\t<tr><td> 4.8959781 </td><td> 0.95320554</td><td> 1         </td></tr>\n",
       "\t<tr><td>-0.5783557 </td><td> 5.44553527</td><td>-1         </td></tr>\n",
       "\t<tr><td> 3.8417831 </td><td> 0.65759443</td><td> 1         </td></tr>\n",
       "\t<tr><td> 2.2649154 </td><td> 4.18082840</td><td>-1         </td></tr>\n",
       "\t<tr><td> 3.8550566 </td><td>-0.08328894</td><td> 1         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " x1 & x2 & y\\\\\n",
       "\\hline\n",
       "\t  3.4781571  & -0.51546992 &  1         \\\\\n",
       "\t  4.8959781  &  0.95320554 &  1         \\\\\n",
       "\t -0.5783557  &  5.44553527 & -1         \\\\\n",
       "\t  3.8417831  &  0.65759443 &  1         \\\\\n",
       "\t  2.2649154  &  4.18082840 & -1         \\\\\n",
       "\t  3.8550566  & -0.08328894 &  1         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | x2 | y | \n",
       "|---|---|---|---|---|---|\n",
       "|  3.4781571  | -0.51546992 |  1          | \n",
       "|  4.8959781  |  0.95320554 |  1          | \n",
       "| -0.5783557  |  5.44553527 | -1          | \n",
       "|  3.8417831  |  0.65759443 |  1          | \n",
       "|  2.2649154  |  4.18082840 | -1          | \n",
       "|  3.8550566  | -0.08328894 |  1          | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1         x2          y \n",
       "1  3.4781571 -0.51546992  1\n",
       "2  4.8959781  0.95320554  1\n",
       "3 -0.5783557  5.44553527 -1\n",
       "4  3.8417831  0.65759443  1\n",
       "5  2.2649154  4.18082840 -1\n",
       "6  3.8550566 -0.08328894  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>-1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>-1</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item -1\n",
       "\\item 1\n",
       "\\item -1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. -1\n",
       "4. 1\n",
       "5. -1\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  1  1 -1  1 -1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(test_data) #printing first few rows\n",
    "head(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load required libraries:\n",
    "library(mvtnorm) # generates multivariate Gaussian sampels and calculate the densities\n",
    "library(ggplot2)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Bayesian Classifier (BC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Build A Bayesian Classifier\n",
    "These are the steps to build a bayesian Classifier:\n",
    "<ol>\n",
    "\t<li>Calculate the class priors $p(\\mathcal{C}_k)$ based on the relative number of training data in each class,</li>\n",
    "\t<li>Calculate the class means $\\mu_k$, class covariance matrices $\\mathbf{S}_k$ and shared covariance matrix $\\Sigma$ using the training data,</li>\n",
    "\t<li>Using the estimated PDF function, calculate $p(x_n|\\mathcal{C}_k)$ for each data point and each class,</li>\n",
    "\t<li>For each test sample, find the class label $\\mathcal{C}_k$ that maximizes the $p(\\mathcal{C}_k)p(x_n|\\mathcal{C}_k)$,</li>\n",
    "</ol>\n",
    "\n",
    "In the following we take these steps one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_classifier <- function(train_data, test_data, train_label, test_label){\n",
    "    \n",
    "    # Initialization of parameters\n",
    "    c0 <- +1; c1 <- -1 # class labels\n",
    "    \n",
    "    # Calculate class probabilities:\n",
    "    p0.hat <- sum(train_label==c0)/nrow(train_data) # total number of samples in class 0 divided by the total nmber \n",
    "    # of training data\n",
    "    p1.hat <- sum(train_label==c1)/nrow(train_data) # or simply 1 - p1.hat\n",
    "\n",
    "    # Estimate class means:\n",
    "    mu0.hat <- colMeans(train_data[train_label==c0,])\n",
    "    mu1.hat <- colMeans(train_data[train_label==c1,])\n",
    "\n",
    "    # class covariance matrices:\n",
    "    sigma0.hat <- var(train_data[train_label==c0,])\n",
    "    sigma1.hat <- var(train_data[train_label==c1,])\n",
    "    \n",
    "    # shared covariance matrix:\n",
    "    sigma.hat <- p0.hat * sigma0.hat + p1.hat * sigma1.hat\n",
    "\n",
    "    # calculate posteriors:\n",
    "    posterior0 <- p0.hat*dmvnorm(x=train_data, mean=mu0.hat, sigma=sigma.hat)\n",
    "    posterior1 <- p1.hat*dmvnorm(x=train_data, mean=mu1.hat, sigma=sigma.hat)\n",
    "\n",
    "    # calculate predictions:\n",
    "    train.predict <- ifelse(posterior0 > posterior1, c0, c1)\n",
    "    test.predict <- ifelse(p0.hat*dmvnorm(x=test_data, mean=mu0.hat, sigma=sigma.hat) > p1.hat*dmvnorm(x=test_data, mean=mu1.hat, sigma=sigma.hat), c0, c1)\n",
    "\n",
    "    # calculate test error:\n",
    "    test_error <- (nrow(test_data) - sum(test_label==test.predict))/nrow(test_data)\n",
    "\n",
    "    return (test_error)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to Build a Logistic Regression\n",
    "Taking the following steps is neccesseary to build a logistic regression:\n",
    "<ol>\n",
    "\t<li>Implement sigmoid function $\\sigma(\\pmb{w}.\\mathbf{x})$, and initialize weight vector $\\pmb{w}$, learning rate $\\eta$ and stopping criterion $\\epsilon$.</li>\n",
    "\t<li>Repeat the followings until the improvement becomes negligible (i.e., $|\\mathcal{L}(\\pmb{w}^{(\\tau+1)})-\\mathcal{L}(\\pmb{w}^{(\\tau)})| \\lt \\epsilon$):\n",
    "<ol>\n",
    "\t<li>Shuffle the training data</li>\n",
    "\t<li>For each datapoint in the training data do:\n",
    "<ol>\n",
    "\t<li>$\\pmb{w}^{(\\tau+1)} := \\pmb{w}^{(\\tau)} - \\eta (\\sigma(\\pmb{w}.\\mathbf{x}) - t_n) \\pmb{x}_n$</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "In the followings, we implement each of these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function that predicts class labels\n",
    "predict <- function(w, X, c0, c1){\n",
    "    sig <- sigmoid(w, X)\n",
    "    return(ifelse(sig>0.5, c1,c0))\n",
    "}\n",
    "    \n",
    "# auxiliary function that calculate a cost function\n",
    "cost <- function (w, X, T, c0){\n",
    "    sig <- sigmoid(w, X)\n",
    "    return(sum(ifelse(T==c0, 1-sig, sig)))\n",
    "}\n",
    "\n",
    "# Sigmoid function (=p(C1|X))\n",
    "sigmoid <- function(w, x){\n",
    "    return(1.0/(1.0+exp(-w%*%t(cbind(1,x)))))    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression <- function(train_data, test_data, train_label, test_label){\n",
    "    \n",
    "    # Initialization of parameters\n",
    "    c0 <- +1; c1 <- -1 # class labels\n",
    "    \n",
    "    # Initializations for Logistic Regression\n",
    "    tau.max <- 1000 # maximum number of iterations\n",
    "    eta <- 0.01 # learning rate\n",
    "    epsilon <- 0.01 # a threshold on the cost (to terminate the process)\n",
    "    \n",
    "    tau <- 1 # iteration counter\n",
    "    terminate <- FALSE\n",
    "    \n",
    "    ## Just a few name/type conversion to make the rest of the code easy to follow\n",
    "    X <- as.matrix(train_data) # rename just for conviniance\n",
    "    T <- ifelse(train_label==c0,0,1) # rename just for conviniance\n",
    "\n",
    "    W <- matrix(,nrow=tau.max, ncol=(ncol(X)+1)) # to be used to store the estimated coefficients\n",
    "    W[1,] <- runif(ncol(W)) # set initial weight\n",
    "\n",
    "    # project data using the sigmoid function (just for convenient)\n",
    "    Y <- sigmoid(W[1,],X)\n",
    "\n",
    "    costs <- data.frame('tau'=1:tau.max)  # to be used to trace the cost in each iteration\n",
    "    costs[1, 'cost'] <- cost(W[1,],X,T, c0)\n",
    "\n",
    "\n",
    "    while(!terminate){\n",
    "        # check termination criteria:\n",
    "        terminate <- tau >= tau.max | cost(W[tau,],X,T, c0)<=epsilon\n",
    "\n",
    "        # shuffle data:\n",
    "        train.index <- sample(1:nrow(train_data), nrow(train_data), replace = FALSE)\n",
    "        X <- X[train.index,]\n",
    "        T <- T[train.index]\n",
    "\n",
    "        # for each datapoint:\n",
    "        for (i in 1:nrow(train_data)){\n",
    "            # check termination criteria:\n",
    "            if (tau >= tau.max | cost(W[tau,],X,T, c0) <=epsilon) {terminate<-TRUE;break}\n",
    "\n",
    "            Y <- sigmoid(W[tau,],X)\n",
    "\n",
    "            # Update the weights\n",
    "            W[(tau+1),] <- W[tau,] - eta * (Y[i]-T[i]) * cbind(1, t(X[i,]))\n",
    "\n",
    "            # record the cost:\n",
    "            costs[(tau+1), 'cost'] <- cost(W[tau,],X,T, c0)\n",
    "\n",
    "            # update the counter:\n",
    "            tau <- tau + 1\n",
    "\n",
    "            # decrease learning rate:\n",
    "            eta = eta * 0.999\n",
    "        }\n",
    "    }\n",
    "    # Done!\n",
    "    costs <- costs[1:tau, ] # remove the NaN tail of the vector (in case of early stopping)\n",
    "\n",
    "    # final result:\n",
    "    w <- W[tau,]\n",
    "    \n",
    "    # calculate predictions:\n",
    "    train.predict <- predict(w,train_data,c0,c1)\n",
    "    test.predict <- predict(w,test_data,c0,c1)\n",
    "\n",
    "    # calculate test error:\n",
    "    test_error <- (nrow(test_data) - sum(test_label==test.predict))/nrow(test_data)\n",
    "    \n",
    "    return (test_error)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of test errors for Bayesian Classifier and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>train_set_size</th><th scope=col>test_errors_BC</th><th scope=col>test_errors_LR</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>  5        </td><td>0.600000000</td><td>0.200000000</td></tr>\n",
       "\t<tr><td> 10        </td><td>0.000000000</td><td>0.000000000</td></tr>\n",
       "\t<tr><td> 15        </td><td>0.000000000</td><td>0.000000000</td></tr>\n",
       "\t<tr><td> 20        </td><td>0.000000000</td><td>0.000000000</td></tr>\n",
       "\t<tr><td> 25        </td><td>0.000000000</td><td>0.000000000</td></tr>\n",
       "\t<tr><td> 30        </td><td>0.000000000</td><td>0.000000000</td></tr>\n",
       "\t<tr><td> 35        </td><td>0.028571429</td><td>0.028571429</td></tr>\n",
       "\t<tr><td> 40        </td><td>0.025000000</td><td>0.025000000</td></tr>\n",
       "\t<tr><td> 45        </td><td>0.022222222</td><td>0.022222222</td></tr>\n",
       "\t<tr><td> 50        </td><td>0.020000000</td><td>0.020000000</td></tr>\n",
       "\t<tr><td> 55        </td><td>0.018181818</td><td>0.018181818</td></tr>\n",
       "\t<tr><td> 60        </td><td>0.016666667</td><td>0.016666667</td></tr>\n",
       "\t<tr><td> 65        </td><td>0.015384615</td><td>0.015384615</td></tr>\n",
       "\t<tr><td> 70        </td><td>0.014285714</td><td>0.014285714</td></tr>\n",
       "\t<tr><td> 75        </td><td>0.013333333</td><td>0.013333333</td></tr>\n",
       "\t<tr><td> 80        </td><td>0.025000000</td><td>0.025000000</td></tr>\n",
       "\t<tr><td> 85        </td><td>0.011764706</td><td>0.011764706</td></tr>\n",
       "\t<tr><td> 90        </td><td>0.011111111</td><td>0.011111111</td></tr>\n",
       "\t<tr><td> 95        </td><td>0.010526316</td><td>0.010526316</td></tr>\n",
       "\t<tr><td>100        </td><td>0.010000000</td><td>0.010000000</td></tr>\n",
       "\t<tr><td>105        </td><td>0.009523810</td><td>0.009523810</td></tr>\n",
       "\t<tr><td>110        </td><td>0.009090909</td><td>0.009090909</td></tr>\n",
       "\t<tr><td>115        </td><td>0.008695652</td><td>0.008695652</td></tr>\n",
       "\t<tr><td>120        </td><td>0.008333333</td><td>0.008333333</td></tr>\n",
       "\t<tr><td>125        </td><td>0.008000000</td><td>0.008000000</td></tr>\n",
       "\t<tr><td>130        </td><td>0.007692308</td><td>0.007692308</td></tr>\n",
       "\t<tr><td>135        </td><td>0.007407407</td><td>0.007407407</td></tr>\n",
       "\t<tr><td>140        </td><td>0.007142857</td><td>0.007142857</td></tr>\n",
       "\t<tr><td>145        </td><td>0.013793103</td><td>0.006896552</td></tr>\n",
       "\t<tr><td>150        </td><td>0.013333333</td><td>0.006666667</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>355        </td><td>0.01971831 </td><td>0.011267606</td></tr>\n",
       "\t<tr><td>360        </td><td>0.01944444 </td><td>0.011111111</td></tr>\n",
       "\t<tr><td>365        </td><td>0.01917808 </td><td>0.010958904</td></tr>\n",
       "\t<tr><td>370        </td><td>0.01621622 </td><td>0.010810811</td></tr>\n",
       "\t<tr><td>375        </td><td>0.01600000 </td><td>0.010666667</td></tr>\n",
       "\t<tr><td>380        </td><td>0.01578947 </td><td>0.015789474</td></tr>\n",
       "\t<tr><td>385        </td><td>0.01818182 </td><td>0.010389610</td></tr>\n",
       "\t<tr><td>390        </td><td>0.01538462 </td><td>0.010256410</td></tr>\n",
       "\t<tr><td>395        </td><td>0.01772152 </td><td>0.015189873</td></tr>\n",
       "\t<tr><td>400        </td><td>0.01500000 </td><td>0.010000000</td></tr>\n",
       "\t<tr><td>405        </td><td>0.01728395 </td><td>0.012345679</td></tr>\n",
       "\t<tr><td>410        </td><td>0.01463415 </td><td>0.009756098</td></tr>\n",
       "\t<tr><td>415        </td><td>0.01445783 </td><td>0.009638554</td></tr>\n",
       "\t<tr><td>420        </td><td>0.01428571 </td><td>0.009523810</td></tr>\n",
       "\t<tr><td>425        </td><td>0.01411765 </td><td>0.009411765</td></tr>\n",
       "\t<tr><td>430        </td><td>0.01395349 </td><td>0.011627907</td></tr>\n",
       "\t<tr><td>435        </td><td>0.01609195 </td><td>0.011494253</td></tr>\n",
       "\t<tr><td>440        </td><td>0.01590909 </td><td>0.013636364</td></tr>\n",
       "\t<tr><td>445        </td><td>0.01573034 </td><td>0.015730337</td></tr>\n",
       "\t<tr><td>450        </td><td>0.01555556 </td><td>0.013333333</td></tr>\n",
       "\t<tr><td>455        </td><td>0.01538462 </td><td>0.010989011</td></tr>\n",
       "\t<tr><td>460        </td><td>0.01521739 </td><td>0.010869565</td></tr>\n",
       "\t<tr><td>465        </td><td>0.01935484 </td><td>0.012903226</td></tr>\n",
       "\t<tr><td>470        </td><td>0.01914894 </td><td>0.012765957</td></tr>\n",
       "\t<tr><td>475        </td><td>0.01894737 </td><td>0.012631579</td></tr>\n",
       "\t<tr><td>480        </td><td>0.01875000 </td><td>0.012500000</td></tr>\n",
       "\t<tr><td>485        </td><td>0.01855670 </td><td>0.014432990</td></tr>\n",
       "\t<tr><td>490        </td><td>0.02040816 </td><td>0.014285714</td></tr>\n",
       "\t<tr><td>495        </td><td>0.02020202 </td><td>0.014141414</td></tr>\n",
       "\t<tr><td>500        </td><td>0.02000000 </td><td>0.014000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " train\\_set\\_size & test\\_errors\\_BC & test\\_errors\\_LR\\\\\n",
       "\\hline\n",
       "\t   5         & 0.600000000 & 0.200000000\\\\\n",
       "\t  10         & 0.000000000 & 0.000000000\\\\\n",
       "\t  15         & 0.000000000 & 0.000000000\\\\\n",
       "\t  20         & 0.000000000 & 0.000000000\\\\\n",
       "\t  25         & 0.000000000 & 0.000000000\\\\\n",
       "\t  30         & 0.000000000 & 0.000000000\\\\\n",
       "\t  35         & 0.028571429 & 0.028571429\\\\\n",
       "\t  40         & 0.025000000 & 0.025000000\\\\\n",
       "\t  45         & 0.022222222 & 0.022222222\\\\\n",
       "\t  50         & 0.020000000 & 0.020000000\\\\\n",
       "\t  55         & 0.018181818 & 0.018181818\\\\\n",
       "\t  60         & 0.016666667 & 0.016666667\\\\\n",
       "\t  65         & 0.015384615 & 0.015384615\\\\\n",
       "\t  70         & 0.014285714 & 0.014285714\\\\\n",
       "\t  75         & 0.013333333 & 0.013333333\\\\\n",
       "\t  80         & 0.025000000 & 0.025000000\\\\\n",
       "\t  85         & 0.011764706 & 0.011764706\\\\\n",
       "\t  90         & 0.011111111 & 0.011111111\\\\\n",
       "\t  95         & 0.010526316 & 0.010526316\\\\\n",
       "\t 100         & 0.010000000 & 0.010000000\\\\\n",
       "\t 105         & 0.009523810 & 0.009523810\\\\\n",
       "\t 110         & 0.009090909 & 0.009090909\\\\\n",
       "\t 115         & 0.008695652 & 0.008695652\\\\\n",
       "\t 120         & 0.008333333 & 0.008333333\\\\\n",
       "\t 125         & 0.008000000 & 0.008000000\\\\\n",
       "\t 130         & 0.007692308 & 0.007692308\\\\\n",
       "\t 135         & 0.007407407 & 0.007407407\\\\\n",
       "\t 140         & 0.007142857 & 0.007142857\\\\\n",
       "\t 145         & 0.013793103 & 0.006896552\\\\\n",
       "\t 150         & 0.013333333 & 0.006666667\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t 355         & 0.01971831  & 0.011267606\\\\\n",
       "\t 360         & 0.01944444  & 0.011111111\\\\\n",
       "\t 365         & 0.01917808  & 0.010958904\\\\\n",
       "\t 370         & 0.01621622  & 0.010810811\\\\\n",
       "\t 375         & 0.01600000  & 0.010666667\\\\\n",
       "\t 380         & 0.01578947  & 0.015789474\\\\\n",
       "\t 385         & 0.01818182  & 0.010389610\\\\\n",
       "\t 390         & 0.01538462  & 0.010256410\\\\\n",
       "\t 395         & 0.01772152  & 0.015189873\\\\\n",
       "\t 400         & 0.01500000  & 0.010000000\\\\\n",
       "\t 405         & 0.01728395  & 0.012345679\\\\\n",
       "\t 410         & 0.01463415  & 0.009756098\\\\\n",
       "\t 415         & 0.01445783  & 0.009638554\\\\\n",
       "\t 420         & 0.01428571  & 0.009523810\\\\\n",
       "\t 425         & 0.01411765  & 0.009411765\\\\\n",
       "\t 430         & 0.01395349  & 0.011627907\\\\\n",
       "\t 435         & 0.01609195  & 0.011494253\\\\\n",
       "\t 440         & 0.01590909  & 0.013636364\\\\\n",
       "\t 445         & 0.01573034  & 0.015730337\\\\\n",
       "\t 450         & 0.01555556  & 0.013333333\\\\\n",
       "\t 455         & 0.01538462  & 0.010989011\\\\\n",
       "\t 460         & 0.01521739  & 0.010869565\\\\\n",
       "\t 465         & 0.01935484  & 0.012903226\\\\\n",
       "\t 470         & 0.01914894  & 0.012765957\\\\\n",
       "\t 475         & 0.01894737  & 0.012631579\\\\\n",
       "\t 480         & 0.01875000  & 0.012500000\\\\\n",
       "\t 485         & 0.01855670  & 0.014432990\\\\\n",
       "\t 490         & 0.02040816  & 0.014285714\\\\\n",
       "\t 495         & 0.02020202  & 0.014141414\\\\\n",
       "\t 500         & 0.02000000  & 0.014000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "train_set_size | test_errors_BC | test_errors_LR | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|   5         | 0.600000000 | 0.200000000 | \n",
       "|  10         | 0.000000000 | 0.000000000 | \n",
       "|  15         | 0.000000000 | 0.000000000 | \n",
       "|  20         | 0.000000000 | 0.000000000 | \n",
       "|  25         | 0.000000000 | 0.000000000 | \n",
       "|  30         | 0.000000000 | 0.000000000 | \n",
       "|  35         | 0.028571429 | 0.028571429 | \n",
       "|  40         | 0.025000000 | 0.025000000 | \n",
       "|  45         | 0.022222222 | 0.022222222 | \n",
       "|  50         | 0.020000000 | 0.020000000 | \n",
       "|  55         | 0.018181818 | 0.018181818 | \n",
       "|  60         | 0.016666667 | 0.016666667 | \n",
       "|  65         | 0.015384615 | 0.015384615 | \n",
       "|  70         | 0.014285714 | 0.014285714 | \n",
       "|  75         | 0.013333333 | 0.013333333 | \n",
       "|  80         | 0.025000000 | 0.025000000 | \n",
       "|  85         | 0.011764706 | 0.011764706 | \n",
       "|  90         | 0.011111111 | 0.011111111 | \n",
       "|  95         | 0.010526316 | 0.010526316 | \n",
       "| 100         | 0.010000000 | 0.010000000 | \n",
       "| 105         | 0.009523810 | 0.009523810 | \n",
       "| 110         | 0.009090909 | 0.009090909 | \n",
       "| 115         | 0.008695652 | 0.008695652 | \n",
       "| 120         | 0.008333333 | 0.008333333 | \n",
       "| 125         | 0.008000000 | 0.008000000 | \n",
       "| 130         | 0.007692308 | 0.007692308 | \n",
       "| 135         | 0.007407407 | 0.007407407 | \n",
       "| 140         | 0.007142857 | 0.007142857 | \n",
       "| 145         | 0.013793103 | 0.006896552 | \n",
       "| 150         | 0.013333333 | 0.006666667 | \n",
       "| ... | ... | ... | \n",
       "| 355         | 0.01971831  | 0.011267606 | \n",
       "| 360         | 0.01944444  | 0.011111111 | \n",
       "| 365         | 0.01917808  | 0.010958904 | \n",
       "| 370         | 0.01621622  | 0.010810811 | \n",
       "| 375         | 0.01600000  | 0.010666667 | \n",
       "| 380         | 0.01578947  | 0.015789474 | \n",
       "| 385         | 0.01818182  | 0.010389610 | \n",
       "| 390         | 0.01538462  | 0.010256410 | \n",
       "| 395         | 0.01772152  | 0.015189873 | \n",
       "| 400         | 0.01500000  | 0.010000000 | \n",
       "| 405         | 0.01728395  | 0.012345679 | \n",
       "| 410         | 0.01463415  | 0.009756098 | \n",
       "| 415         | 0.01445783  | 0.009638554 | \n",
       "| 420         | 0.01428571  | 0.009523810 | \n",
       "| 425         | 0.01411765  | 0.009411765 | \n",
       "| 430         | 0.01395349  | 0.011627907 | \n",
       "| 435         | 0.01609195  | 0.011494253 | \n",
       "| 440         | 0.01590909  | 0.013636364 | \n",
       "| 445         | 0.01573034  | 0.015730337 | \n",
       "| 450         | 0.01555556  | 0.013333333 | \n",
       "| 455         | 0.01538462  | 0.010989011 | \n",
       "| 460         | 0.01521739  | 0.010869565 | \n",
       "| 465         | 0.01935484  | 0.012903226 | \n",
       "| 470         | 0.01914894  | 0.012765957 | \n",
       "| 475         | 0.01894737  | 0.012631579 | \n",
       "| 480         | 0.01875000  | 0.012500000 | \n",
       "| 485         | 0.01855670  | 0.014432990 | \n",
       "| 490         | 0.02040816  | 0.014285714 | \n",
       "| 495         | 0.02020202  | 0.014141414 | \n",
       "| 500         | 0.02000000  | 0.014000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    train_set_size test_errors_BC test_errors_LR\n",
       "1     5            0.600000000    0.200000000   \n",
       "2    10            0.000000000    0.000000000   \n",
       "3    15            0.000000000    0.000000000   \n",
       "4    20            0.000000000    0.000000000   \n",
       "5    25            0.000000000    0.000000000   \n",
       "6    30            0.000000000    0.000000000   \n",
       "7    35            0.028571429    0.028571429   \n",
       "8    40            0.025000000    0.025000000   \n",
       "9    45            0.022222222    0.022222222   \n",
       "10   50            0.020000000    0.020000000   \n",
       "11   55            0.018181818    0.018181818   \n",
       "12   60            0.016666667    0.016666667   \n",
       "13   65            0.015384615    0.015384615   \n",
       "14   70            0.014285714    0.014285714   \n",
       "15   75            0.013333333    0.013333333   \n",
       "16   80            0.025000000    0.025000000   \n",
       "17   85            0.011764706    0.011764706   \n",
       "18   90            0.011111111    0.011111111   \n",
       "19   95            0.010526316    0.010526316   \n",
       "20  100            0.010000000    0.010000000   \n",
       "21  105            0.009523810    0.009523810   \n",
       "22  110            0.009090909    0.009090909   \n",
       "23  115            0.008695652    0.008695652   \n",
       "24  120            0.008333333    0.008333333   \n",
       "25  125            0.008000000    0.008000000   \n",
       "26  130            0.007692308    0.007692308   \n",
       "27  135            0.007407407    0.007407407   \n",
       "28  140            0.007142857    0.007142857   \n",
       "29  145            0.013793103    0.006896552   \n",
       "30  150            0.013333333    0.006666667   \n",
       "... ...            ...            ...           \n",
       "71  355            0.01971831     0.011267606   \n",
       "72  360            0.01944444     0.011111111   \n",
       "73  365            0.01917808     0.010958904   \n",
       "74  370            0.01621622     0.010810811   \n",
       "75  375            0.01600000     0.010666667   \n",
       "76  380            0.01578947     0.015789474   \n",
       "77  385            0.01818182     0.010389610   \n",
       "78  390            0.01538462     0.010256410   \n",
       "79  395            0.01772152     0.015189873   \n",
       "80  400            0.01500000     0.010000000   \n",
       "81  405            0.01728395     0.012345679   \n",
       "82  410            0.01463415     0.009756098   \n",
       "83  415            0.01445783     0.009638554   \n",
       "84  420            0.01428571     0.009523810   \n",
       "85  425            0.01411765     0.009411765   \n",
       "86  430            0.01395349     0.011627907   \n",
       "87  435            0.01609195     0.011494253   \n",
       "88  440            0.01590909     0.013636364   \n",
       "89  445            0.01573034     0.015730337   \n",
       "90  450            0.01555556     0.013333333   \n",
       "91  455            0.01538462     0.010989011   \n",
       "92  460            0.01521739     0.010869565   \n",
       "93  465            0.01935484     0.012903226   \n",
       "94  470            0.01914894     0.012765957   \n",
       "95  475            0.01894737     0.012631579   \n",
       "96  480            0.01875000     0.012500000   \n",
       "97  485            0.01855670     0.014432990   \n",
       "98  490            0.02040816     0.014285714   \n",
       "99  495            0.02020202     0.014141414   \n",
       "100 500            0.02000000     0.014000000   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating a sample sequence of training data size points from 5 to until all points of training data\n",
    "sample <- seq(from = 5, to = nrow(train_data), by = 5)\n",
    "\n",
    "# empty data frame to store test errors for Bayesian Classifier and Logistic Regression\n",
    "test_error <- data.frame('train_set_size' = rep(0,length(sample)), 'test_errors_BC' = rep(0,length(sample)), 'test_errors_LR' = rep(0,length(sample)))\n",
    "\n",
    "ind <- 1 # iteration index to store test errors\n",
    "\n",
    "#for each train data size\n",
    "for (s in sample){\n",
    "    #slicing train data, train label, test data, test label\n",
    "    sample_train <- train_data[1:s,1:2] \n",
    "    sample_test <- test_data[1:s,1:2]\n",
    "    sample_train_label <- train_label[1:s]\n",
    "    sample_test_label <- test_label[1:s]\n",
    "    \n",
    "    #updating dataframe\n",
    "    test_error[ind, 1] <- s\n",
    "    #calling bayesian_classifier function\n",
    "    test_error[ind, 2] <- bayesian_classifier(sample_train, sample_test, sample_train_label, sample_test_label)\n",
    "    #calling logistic_regression function\n",
    "    test_error[ind, 3] <- logistic_regression(sample_train, sample_test, sample_train_label, sample_test_label)\n",
    "    ind <- ind + 1 #incrementing index\n",
    "}\n",
    "test_error #printing test errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot test error vs training data size for Bayesian Classifier and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAABmJLR0QA/wD/AP+gvaeTAAAg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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the test error for each model (with different colors) versus the size of the training set\n",
    "\n",
    "test_error_melt <- melt(test_error, id='train_set_size')\n",
    "names(test_error_melt) <- c('train_set_size', 'type','test_error')\n",
    "ggplot(data=test_error_melt, aes(x = train_set_size, y = test_error, color=type)) + geom_line(size=.75) + \n",
    "        labs(title='Test Error vs Training Data size', x = \"Training Set Size\", y = \"Test Error\") +  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does happen for each classifier when the number of training data points is increased?**\n",
    "    \n",
    "At first, the test errors for both bayesian classifier and logistic regression reduces to zero when the training dataset size increases from 5 to 30. The test errors for both the algorithms slightly increases and is equal when the training dataset size increases from 30 to 140. After 140, the test errors slightly increase again and fluctuates for different sizes of training dataset.\n",
    "       \n",
    "**Which classifier is best suited when the training set is small, and which is best suited when the training set is big?**\n",
    " \n",
    "From the above plot, we observe that the test error for logistic regression is always less than the bayesian classifier. So, for this given data, logistic regression is suitable for both small and big training sets. This could be different for other data sets. We can infer that bayesian classifier is also suitable for smaller data sets. \n",
    "\n",
    "**Possible reasons for the above observations:**\n",
    "\n",
    "Complex models need large training datasets to fit perfectly. If we try to fit complex model on small data, it would result in overfitting, leading to large variance and thus large test errors. So, for a given model, when we increase size of training data, we can expect a fall in test error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
